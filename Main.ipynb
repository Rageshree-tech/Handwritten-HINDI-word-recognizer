{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52caaf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853cd86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_clear(image):\n",
    "    thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    thresh = cv2.GaussianBlur(thresh, (3,3), 1)\n",
    "    kernel1 = np.ones((3,3), np.uint8)\n",
    "    thresh = cv2.erode(thresh, kernel1, iterations = 1)\n",
    "    ret,thresh=cv2.threshold(thresh,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    kernel2 = np.ones((3,3), np.uint8)\n",
    "    thresh = cv2.dilate(thresh, kernel2, iterations = 1)\n",
    "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh, None, None, None, 8, cv2.CV_32S)\n",
    "    areas = stats[1:,cv2.CC_STAT_AREA]\n",
    "    result = np.zeros((labels.shape), np.uint8)\n",
    "    for i in range(0, nlabels - 1):\n",
    "        if areas[i] >= 100:\n",
    "            result[labels == i + 1] = 255\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30c4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_skrew_correction(thresh):\n",
    "    coords = np.column_stack(np.where(thresh > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle > 45:\n",
    "        angle = -angle+90\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = thresh.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(thresh, M, (w, h),flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    rotated = cv2.bitwise_not(rotated)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ec04c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(image):\n",
    "    row = []\n",
    "    h, w = image.shape\n",
    "    for i in range(0, int(h*0.75)):\n",
    "        cnt = list(image[i]).count(0)\n",
    "        row.append(cnt)\n",
    "    row_id = row.index(max(row))\n",
    "    row_cnt = row[row_id]\n",
    "    for i in range(0, row_id):\n",
    "        image[i] = 255\n",
    "    for i in range(0, int((h-row_id)*0.2)):\n",
    "        cnt = list(image[row_id+i]).count(0)\n",
    "        if cnt >= row_cnt*0.2:\n",
    "            image[row_id+i] = 255\n",
    "        else:\n",
    "            break\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9838918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanArea(contours):\n",
    "    meanArea=0\n",
    "    for contour in contours:\n",
    "        meanArea+=cv2.contourArea(contour)\n",
    "    meanArea=(meanArea)/len(contours)\n",
    "    return meanArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8470f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_extraction(original,image):\n",
    "    image = cv2.bitwise_not(image)\n",
    "    contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    meanArea = getMeanArea(contours)\n",
    "    count=0\n",
    "    coords=[]\n",
    "    coordinates = []\n",
    "    for contour in contours:\n",
    "        (x,y,w,h)=cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour)>0.5*meanArea:\n",
    "            coordinates.append((x,y,w,h))\n",
    "    coordinates.sort(key = lambda x: x[0])\n",
    "    n = len(coordinates)\n",
    "    coordinates_final = []\n",
    "    index = 0\n",
    "    while(index < n-1):\n",
    "        x1 = coordinates[index+1][0]\n",
    "        x2 = coordinates[index][0]+coordinates[index][2]\n",
    "        if(x2 > x1):\n",
    "            x = coordinates[index][0]\n",
    "            y = coordinates[index][1]\n",
    "            w = coordinates[index+1][0]+coordinates[index+1][2]-coordinates[index][0]\n",
    "            h = max(coordinates[index][3],coordinates[index][3])\n",
    "            coordinates_final.append((x,y,w,h))\n",
    "            index += 1\n",
    "        else:\n",
    "            coordinates_final.append(coordinates[index])\n",
    "        index += 1\n",
    "    if index == n-1:\n",
    "        coordinates_final.append(coordinates[index])\n",
    "    for coordis in coordinates_final:\n",
    "        (x,y,w,h) = coordis\n",
    "        if w / h > 1.4:\n",
    "            half_width = int(w / 2)\n",
    "            coords.append((x, y, half_width, h))\n",
    "            coords.append((x + half_width, y, half_width, h))\n",
    "            count=count+2\n",
    "        else:\n",
    "            coords.append((x, y, w, h))\n",
    "            count=count+1\n",
    "    coords.sort(key = lambda x: x[0])\n",
    "    output_array = []\n",
    "    for i in range(count):\n",
    "        x = coords[i][0]\n",
    "        y = coords[i][1]\n",
    "        z = min(15,y)\n",
    "        y -= z\n",
    "        w = coords[i][2]\n",
    "        h = coords[i][3]+z\n",
    "        result = original[y:y+h,x:x+w]\n",
    "        result = cv2.resize(result,(100,100))\n",
    "        outputImage = cv2.copyMakeBorder(\n",
    "                         result, \n",
    "                         5, \n",
    "                         5, \n",
    "                         5, \n",
    "                         5, \n",
    "                         cv2.BORDER_CONSTANT, \n",
    "                         value=255\n",
    "                      )\n",
    "        filename='character'+str(i+1)+'.jpg'\n",
    "        cv2.imwrite(filename,cv2.bitwise_not(outputImage))\n",
    "        cv2.imshow(str(i+1),outputImage)\n",
    "        output_array.append(filename)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return output_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec49621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    h, w = image.shape\n",
    "    image = cv2.resize(image,(int(w/2), int(h/2)))\n",
    "    # thresh is image with threshold applied any image is converted to binary\n",
    "    thresh = image_clear(image.copy())\n",
    "    # img is the converted image with horizontal alignment \n",
    "    img = image_skrew_correction(thresh.copy())\n",
    "    # final_img is the image with header line deleted\n",
    "    final_img = remove_header(img.copy())\n",
    "    cv2.imshow('final',final_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    image_paths = character_extraction(img,final_img.copy())\n",
    "    output = []\n",
    "    for i in image_paths:\n",
    "        m = []\n",
    "        image = cv2.imread(i,cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image,(32,32))\n",
    "        image = np.reshape(image,(32,32,1))/255\n",
    "        m.append(image)\n",
    "        m = np.array(m)\n",
    "        y_classes = np.argmax(model.predict(m))\n",
    "        output.append(catergories[y_classes])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b41485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model_hindi.hdf5')\n",
    "CATEGORIES = ['क','घ','च','ज','ञ','ट','ठ','ड','त','द','ध','न',\n",
    "              'प','फ','ब','म','र','ल','व','ष','स','ह','क्ष','त्र','ज्ञ']\n",
    "catergories = np.array(CATEGORIES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a8b123",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(answer))\u001b[38;5;66;03m# will be the output string\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_images/t8.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,image_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(image_paths):\n\u001b[1;32m----> 5\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(answer))\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(image_path):\n\u001b[0;32m      2\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     h, w \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m      4\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image,(\u001b[38;5;28mint\u001b[39m(w\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), \u001b[38;5;28mint\u001b[39m(h\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# thresh is image with threshold applied any image is converted to binary\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    #Enter filenames to be tested in image_paths after adding them to this folder\n",
    "    image_paths = ['sample_images/t8.jpg']\n",
    "    for i,image_path in enumerate(image_paths):\n",
    "        answer = predict(image_path)\n",
    "        print(''.join(answer))# will be the output string\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d82a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
